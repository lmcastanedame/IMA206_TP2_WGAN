{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzo652OIfgkQ"
      },
      "source": [
        "# Exercise 2: Convolution GAN for MNIST digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS78gxFngGi-"
      },
      "source": [
        "This practical session is based on the [DCGAN Pytorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html).\n",
        "\n",
        "It was adapted by\n",
        "* Lucía Bouza\n",
        "* Bruno Galerne\n",
        "* Arthur Leclaire\n",
        "\n",
        "You should complete the code regions marked with ###...###."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds7HbRCmgCwu"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LHhzJBLSNOh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import torchvision.utils as vutils\n",
        "import torch.utils.data as data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import torchvision\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device is\", device)\n",
        "# !nvidia-smi\n",
        "\n",
        "# Displaying function\n",
        "def imshow(img,size=None):\n",
        "    img = img*0.5 + 0.5     # unnormalize\n",
        "    if size is not None:\n",
        "        img = transforms.Resize(size=size, interpolation=transforms.InterpolationMode.NEAREST, antialias=True)(img)\n",
        "    pil_img = torchvision.transforms.functional.to_pil_image(img)\n",
        "    display(pil_img)\n",
        "    # print(\"Image size (h x w): \",  pil_img.height, \"x\", pil_img.width)\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x11o4K94h6CY"
      },
      "source": [
        "## Download MNIST dataset\n",
        "\n",
        "Note that we normalize the images between -1 and 1 because during sampling, we have to limit the input space and scaling between -1 and 1 makes it easier to implement it. We discard the last batch so that all batches have the same size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2Scj6lGiByO"
      },
      "outputs": [],
      "source": [
        "batch_size=128\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
        "train_set = MNIST(os.getcwd(), train=True, transform=transform, download=True)\n",
        "train_loader = data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amXLc6glhcP2"
      },
      "source": [
        "QUESTION: Draw a batch of real images with the train_loader and display them. Use `next` and `iter` to get a batch from `train_loader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD7NjgIwhcP2"
      },
      "outputs": [],
      "source": [
        "real,_ = next(iter(train_loader))\n",
        "print(real.shape)\n",
        "\n",
        "pil_img = imshow(torchvision.utils.make_grid(real.to('cpu'),nrow=16))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5fs7sxuQyY8"
      },
      "source": [
        "## Generator and Discriminator Models\n",
        "\n",
        "The architecture of DCGAN is described in the [(Radford et al., 2016)](https://arxiv.org/pdf/1511.06434.pdf)\n",
        "\n",
        "QUESTION: Examine the architecture of the following generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbyuGWJQREbg"
      },
      "outputs": [],
      "source": [
        "# Size  of generator input\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator and discriminator\n",
        "ngf, ndf = 64, 64\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels = nz, out_channels = ngf * 8, kernel_size = 4, stride = 1, padding = 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(in_channels = ngf * 8, out_channels = ngf * 4, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(in_channels = ngf * 4, out_channels = ngf * 2, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(in_channels = ngf * 2, out_channels = ngf, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(in_channels = ngf, out_channels = 1, kernel_size=1, stride=1, padding=2, bias=False),\n",
        "            nn.Tanh()\n",
        "            # output size. 1 x 28 x 28\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is 1 x 28 x 28\n",
        "            nn.Conv2d(in_channels = 1, out_channels = ndf, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 15 x 15\n",
        "            nn.Conv2d(in_channels = ndf, out_channels= ndf * 2, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 8 x 8\n",
        "            nn.Conv2d(in_channels = ndf * 2, out_channels = ndf * 4, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 5 x 5\n",
        "            nn.Conv2d(in_channels = ndf * 4, out_channels = 1, kernel_size = 4, stride = 2, padding = 1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input).view(-1, 1).squeeze(1)\n",
        "\n",
        "# check sizes:\n",
        "# import torchsummary\n",
        "\n",
        "# # Create some generator and discriminator\n",
        "# netG = Generator().to(device)\n",
        "# netD = Discriminator().to(device)\n",
        "\n",
        "# torchsummary.summary(netG, input_size=(nz,1,1))\n",
        "# torchsummary.summary(netD, input_size=(1,28,28))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGbRhkOJhcP3"
      },
      "source": [
        "## Display Samples of the Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oLYU5_llQ3O"
      },
      "outputs": [],
      "source": [
        "# function to display samples of the generator\n",
        "def show(G,z=None,batch_size=128,nz=100):\n",
        "  # provide random latent code as option to see evolution\n",
        "  with torch.no_grad():\n",
        "    if z==None:\n",
        "      z = torch.randn(batch_size,nz,1,1).to(device)\n",
        "    genimages = G(z)\n",
        "    pil_img = imshow(torchvision.utils.make_grid(genimages.to('cpu'),nrow=16))\n",
        "    return(pil_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibgOtzGg6Xx4"
      },
      "source": [
        "## Weight initialization\n",
        "\n",
        "The DCGAN [paper](https://arxiv.org/pdf/1511.06434.pdf) mentions that all model weights shall be randomly initialized from a Normal distribution with $\\mu=0$ and $\\sigma=0.02$. We implement `weights_init` function to reinitialize the weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZDe_VPeRqTg",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "# Create the generator and discriminator\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights to mean=0, stdev=0.02.\n",
        "G.apply(weights_init);\n",
        "D.apply(weights_init);\n",
        "\n",
        "show(G);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iCw1um-hcP5"
      },
      "source": [
        "<br/><br/><br/><br/><br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GswgbnEDwviP"
      },
      "source": [
        "# Part 1: DCGAN Training with WGAN-GP loss\n",
        "\n",
        "<br/><br/>\n",
        "**QUESTION:** Implement WGAN-GP training for MNIST by completing the code in the following cell.\n",
        "We recall the pseudo-code:\n",
        "\n",
        "> For each batch of images $x_{\\text{real}}$:\n",
        ">\n",
        "> **1) Train discriminator:**\n",
        "> > Generate $z$ a tensor of size $b\\times nz\\times 1\\times 1$ of idd Gaussian variables  \n",
        "> > Generate  $x_{\\text{fake}} = \\mathtt{G}(z)$ a set $b$ fake images  \n",
        "> > Compute the discriminator loss to maximize <br/>\n",
        "> > Compute the gradient and do an optimizer step for the disciminator parameters  \n",
        ">\n",
        "> **2) Train the generator:**\n",
        "> > Generate $z$ a new tensor of size $b\\times nz\\times 1\\times 1$ of idd Gaussian variables  \n",
        "> > Compute the generator loss to minimize <br/>\n",
        "> > Compute the gradient and do an optimizer step for the generator parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJZt2vxChcP5"
      },
      "outputs": [],
      "source": [
        "def lipconstant(D,x,y):\n",
        "    ### ... ###\n",
        "\n",
        "\n",
        "def gradient_penalty(D,x,y):\n",
        "    ### ... ###\n",
        "\n",
        "\n",
        "y = next(iter(train_loader))[0].to(device)\n",
        "x = G(torch.randn(batch_size, nz, 1, 1, device=device)).detach()\n",
        "\n",
        "print(lipconstant(D,x,y))\n",
        "print(gradient_penalty(D,x,y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "xYwYdprhhcP6"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)  # initialize random seed for reproducibility\n",
        "\n",
        "num_epochs = 5\n",
        "log_every = 100\n",
        "gpw = 0.1\n",
        "\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "G.apply(weights_init);\n",
        "D.apply(weights_init);\n",
        "\n",
        "optimD = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimG = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "zviz = torch.randn(batch_size,nz,1,1).to(device)\n",
        "\n",
        "t0 = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    # For each batch in the train_loader\n",
        "    for i, batch in enumerate(train_loader, 0):\n",
        "\n",
        "        ############################\n",
        "        # Batchs of real and fake images\n",
        "        real = batch[0].to(device)\n",
        "        fake = G(torch.randn(batch_size, nz, 1, 1, device=device))\n",
        "        faked = fake.detach()\n",
        "\n",
        "        ############################\n",
        "        # Update D network\n",
        "        ### ... ###\n",
        "\n",
        "        ############################\n",
        "        # Update G network\n",
        "        ### ... ###\n",
        "\n",
        "        ############################\n",
        "        # Display training stats and visualize\n",
        "        if i % log_every == 0:\n",
        "            print('[%d/%d][%d/%d][%.4f s]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tLip(D): %.4f'\n",
        "                  % (epoch+1, num_epochs, i, len(train_loader), time.time()-t0, Dloss.item(), Gloss.item(),lipconstant(D,real,faked)))\n",
        "            show(G,zviz)\n",
        "\n",
        "print('Total learning time = ',time.time()-t0)\n",
        "\n",
        "# Save final generator in a variable for later use\n",
        "wgan = Generator()\n",
        "wgan.load_state_dict(G.state_dict())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4klvQ8a8hcP6"
      },
      "outputs": [],
      "source": [
        "# Save final generator for later use\n",
        "torch.save(G.state_dict(), 'wgan.pt')\n",
        "wgan = Generator()\n",
        "wgan.load_state_dict(G.state_dict())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH2PKZcdhcP6"
      },
      "source": [
        "<br/><br/><br/><br/><br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYn2sq3GhcP6"
      },
      "source": [
        "# Part 2 BONUS: Let's play with the Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXbp5DXM__0K"
      },
      "source": [
        "## Interpolation in latent space:\n",
        "\n",
        "**QUESTION:**\n",
        "Generate 2 sets of 10 latent variable $z_0$ and $z_1$ and display the generated images by the latent variables:\n",
        "$$\n",
        "z_\\alpha = (1-\\alpha) z_0 + \\alpha z_1\n",
        "$$\n",
        "for $\\alpha$ varying between $0$ and $1$.\n",
        "\n",
        "Display all the images in a grid of height 10 and width 20 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmGx53H7uvsa",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# You may load a trained generator from a file\n",
        "# G = Generator().to(device)\n",
        "# G.load_state_dict(torch.load('wgan_epoch100.pt'))\n",
        "# G.eval();  # Turn generator in evaluation mode to fix BatchNorm layers\n",
        "\n",
        "minib = 10\n",
        "nk = 30\n",
        "\n",
        "z0 = torch.randn(minib, nz, 1, 1, device=device)\n",
        "z1 = torch.randn(minib, nz, 1, 1, device=device)\n",
        "\n",
        "genimages = torch.zeros((minib*nk,1,28,28))\n",
        "for k in np.arange(nk):\n",
        "    ### ... ###\n",
        "\n",
        "pil_img = imshow(torchvision.utils.make_grid(genimages.to('cpu'),nrow=nk))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_opnQ13mhcP7"
      },
      "source": [
        "## Nearest Neighbor in the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uigD4ZWEhcP7"
      },
      "outputs": [],
      "source": [
        "# load all the database\n",
        "train_loader_all = data.DataLoader(train_set, batch_size=60000, shuffle=False, num_workers=2, drop_last=True)\n",
        "y,labels = next(iter(train_loader_all))\n",
        "\n",
        "realzeros = y[labels==0]\n",
        "realones = y[labels==1]\n",
        "realtwos = y[labels==2]\n",
        "realthrees = y[labels==3]\n",
        "imshow(torchvision.utils.make_grid(realzeros[0:128,:,:,:].to('cpu'),nrow=16));\n",
        "imshow(torchvision.utils.make_grid(realones[0:128,:,:,:].to('cpu'),nrow=16));\n",
        "imshow(torchvision.utils.make_grid(realtwos[0:128,:,:,:].to('cpu'),nrow=16));\n",
        "imshow(torchvision.utils.make_grid(realthrees[0:128,:,:,:].to('cpu'),nrow=16));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPjVdztchcP8"
      },
      "source": [
        "**QUESTION:** For several samples of the generative model, compute the nearest neighbors in the whole dataset.\n",
        "\n",
        "Display the samples and their nearest neighbor side by side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tn6F-GmhcP8"
      },
      "outputs": [],
      "source": [
        "### ... ###"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}